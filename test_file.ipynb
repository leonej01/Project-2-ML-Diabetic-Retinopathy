{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Letter Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lettr</th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lettr  x-box  y-box  width  high  onpix  x-bar  y-bar  x2bar  y2bar  \\\n",
       "0         T      2      8      3     5      1      8     13      0      6   \n",
       "1         I      5     12      3     7      2     10      5      5      4   \n",
       "2         D      4     11      6     8      6     10      6      2      6   \n",
       "3         N      7     11      6     6      3      5      9      4      6   \n",
       "4         G      2      1      3     1      1      8      6      6      6   \n",
       "...     ...    ...    ...    ...   ...    ...    ...    ...    ...    ...   \n",
       "19995     D      2      2      3     3      2      7      7      7      6   \n",
       "19996     C      7     10      8     8      4      4      8      6      9   \n",
       "19997     T      6      9      6     7      5      6     11      3      7   \n",
       "19998     S      2      3      4     2      1      8      7      2      6   \n",
       "19999     A      4      9      6     6      2      9      5      3      1   \n",
       "\n",
       "       xybar  x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n",
       "0          6     10      8      0      8      0      8  \n",
       "1         13      3      9      2      8      4     10  \n",
       "2         10      3      7      3      7      3      9  \n",
       "3          4      4     10      6     10      2      8  \n",
       "4          6      5      9      1      7      5     10  \n",
       "...      ...    ...    ...    ...    ...    ...    ...  \n",
       "19995      6      6      4      2      8      3      7  \n",
       "19996     12      9     13      2      9      3      7  \n",
       "19997     11      9      5      2     12      2      4  \n",
       "19998     10      6      8      1      9      5      8  \n",
       "19999      8      1      8      2      7      2      8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in data\n",
    "df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m13/lesson_3/datasets/letter-recognition.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x-box  y-box  width  high  onpix  x-bar  y-bar  x2bar  y2bar  xybar  \\\n",
       "0          2      8      3     5      1      8     13      0      6      6   \n",
       "1          5     12      3     7      2     10      5      5      4     13   \n",
       "2          4     11      6     8      6     10      6      2      6     10   \n",
       "3          7     11      6     6      3      5      9      4      6      4   \n",
       "4          2      1      3     1      1      8      6      6      6      6   \n",
       "...      ...    ...    ...   ...    ...    ...    ...    ...    ...    ...   \n",
       "19995      2      2      3     3      2      7      7      7      6      6   \n",
       "19996      7     10      8     8      4      4      8      6      9     12   \n",
       "19997      6      9      6     7      5      6     11      3      7     11   \n",
       "19998      2      3      4     2      1      8      7      2      6     10   \n",
       "19999      4      9      6     6      2      9      5      3      1      8   \n",
       "\n",
       "       x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n",
       "0         10      8      0      8      0      8  \n",
       "1          3      9      2      8      4     10  \n",
       "2          3      7      3      7      3      9  \n",
       "3          4     10      6     10      2      8  \n",
       "4          5      9      1      7      5     10  \n",
       "...      ...    ...    ...    ...    ...    ...  \n",
       "19995      6      4      2      8      3      7  \n",
       "19996      9     13      2      9      3      7  \n",
       "19997      9      5      2     12      2      4  \n",
       "19998      6      8      1      9      5      8  \n",
       "19999      1      8      2      7      2      8  \n",
       "\n",
       "[20000 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the label to create the X data\n",
    "X = df.drop('lettr', axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        T\n",
       "1        I\n",
       "2        D\n",
       "3        N\n",
       "4        G\n",
       "        ..\n",
       "19995    D\n",
       "19996    C\n",
       "19997    T\n",
       "19998    S\n",
       "19999    A\n",
       "Name: lettr, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the y set from the \"lettr\" column\n",
    "y = df[\"lettr\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets using random_state=1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 22, 19, ..., 19, 12,  5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the y data with the label encoder\n",
    "# Create an instance of the label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the y training and testing data using the label encoder\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05709539, -0.61854094, -0.55159253, ..., -0.86818471,\n",
       "         0.51106956,  0.73411898],\n",
       "       [ 0.51134711, -0.31504697, -0.05606112, ...,  1.71736562,\n",
       "        -1.04162544, -0.49700458],\n",
       "       [-1.05709539, -0.92203491, -1.54265534, ...,  1.71736562,\n",
       "        -1.04162544, -0.49700458],\n",
       "       ...,\n",
       "       [ 1.55697544,  0.59543493,  0.43947029, ..., -0.22179713,\n",
       "        -0.26527794, -2.34368991],\n",
       "       [-0.53428122, -1.83251681, -0.55159253, ..., -2.16095988,\n",
       "        -0.65345169,  0.1185572 ],\n",
       "       [-0.01146706,  0.29194096, -0.05606112, ...,  1.07097804,\n",
       "        -0.26527794, -1.72812814]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the X data by using StandardScaler()\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01146706, -0.31504697, -0.55159253, ..., -0.22179713,\n",
       "        -0.26527794,  0.1185572 ],\n",
       "       [-1.05709539, -1.22552887, -1.54265534, ..., -0.22179713,\n",
       "        -0.65345169, -0.49700458],\n",
       "       [-0.53428122, -0.92203491, -0.55159253, ...,  1.71736562,\n",
       "        -1.04162544,  0.1185572 ],\n",
       "       ...,\n",
       "       [ 1.03416128,  1.20242287,  0.43947029, ...,  1.07097804,\n",
       "         0.8992433 ,  0.1185572 ],\n",
       "       [-0.53428122, -0.61854094, -0.05606112, ..., -0.22179713,\n",
       "        -1.42979918,  0.1185572 ],\n",
       "       [ 0.51134711,  0.29194096,  1.4305331 , ..., -0.22179713,\n",
       "         0.8992433 , -1.72812814]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test dataset based on the fit from the training dataset\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.7766 (+/- 0.0076)\n",
      "SVM: 0.9366 (+/- 0.0045)\n",
      "KNN: 0.9339 (+/- 0.0008)\n",
      "Decision Tree: 0.8623 (+/- 0.0038)\n",
      "Random Forest: 0.9561 (+/- 0.0031)\n",
      "Extremely Random Trees: 0.9661 (+/- 0.0028)\n",
      "Gradient Boosting: 0.9131 (+/- 0.0037)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferleone/Desktop/AI_Bootcamp/13-Classification/3/Activities/.conda/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/jenniferleone/Desktop/AI_Bootcamp/13-Classification/3/Activities/.conda/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/jenniferleone/Desktop/AI_Bootcamp/13-Classification/3/Activities/.conda/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/jenniferleone/Desktop/AI_Bootcamp/13-Classification/3/Activities/.conda/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/jenniferleone/Desktop/AI_Bootcamp/13-Classification/3/Activities/.conda/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost: 0.2515 (+/- 0.0181)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      1.00      0.99       202\n",
      "           B       0.89      0.96      0.93       200\n",
      "           C       0.99      0.98      0.98       182\n",
      "           D       0.91      0.97      0.94       197\n",
      "           E       0.94      0.96      0.95       178\n",
      "           F       0.95      0.95      0.95       177\n",
      "           G       0.97      0.96      0.97       188\n",
      "           H       0.95      0.90      0.92       181\n",
      "           I       0.96      0.96      0.96       170\n",
      "           J       0.98      0.95      0.97       174\n",
      "           K       0.91      0.94      0.92       164\n",
      "           L       0.99      0.98      0.99       174\n",
      "           M       0.96      0.97      0.97       188\n",
      "           N       0.98      0.93      0.95       200\n",
      "           O       0.94      0.93      0.94       218\n",
      "           P       0.97      0.95      0.96       215\n",
      "           Q       0.94      0.99      0.96       190\n",
      "           R       0.92      0.91      0.91       193\n",
      "           S       0.97      0.95      0.96       212\n",
      "           T       1.00      0.97      0.98       215\n",
      "           U       0.99      0.97      0.98       208\n",
      "           V       0.96      0.97      0.96       183\n",
      "           W       0.99      0.99      0.99       193\n",
      "           X       0.97      0.98      0.97       203\n",
      "           Y       0.99      0.97      0.98       200\n",
      "           Z       0.99      0.97      0.98       195\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.96      0.96      0.96      5000\n",
      "weighted avg       0.96      0.96      0.96      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Models\n",
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression()),\n",
    "    (\"SVM\", SVC()),\n",
    "    (\"KNN\", KNeighborsClassifier()),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "    (\"Random Forest\", RandomForestClassifier()),\n",
    "    (\"Extremely Random Trees\", ExtraTreesClassifier()),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier()),\n",
    "    (\"AdaBoost\", AdaBoostClassifier())\n",
    "]\n",
    "\n",
    "# Create a Pipeline and Evaluate Each Model\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    cv_scores = cross_val_score(pipeline, X_train_scaled, y_train_encoded, cv=5, scoring='accuracy')\n",
    "    \n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    \n",
    "    print(f\"{name}: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "    \n",
    "    \n",
    "    \n",
    "# Detailed Evaluation: \n",
    "# Example for a single model, e.g., the Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Fit to a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the logistic regression classifier model with a random_state of 1\n",
    "lr_model = LogisticRegression(random_state=1, max_iter=500)\n",
    "\n",
    "# Fit the model to the training data\n",
    "lr_model.fit(X_train_scaled, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model by checking the model accuracy with model.score\n",
    "print(f\"Training Data Score: {lr_model.score(X_train_scaled, y_train_encoded)}\")\n",
    "print(f\"Testing Data Score: {lr_model.score(X_test_scaled, y_test_encoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Fit to a Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the support vector machine classifier model with a 'rbf' kernel\n",
    "svm_model = SVC(kernel='rbf')\n",
    "svm_model = SVC(kernel=\"\")\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm_model.fit(X_train_scaled, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model by checking the model accuracy with model.score\n",
    "print(f\"Training Data Score: {svm_model.score(X_train_scaled, y_train_encoded)}\")\n",
    "print(f\"Testing Data Score: {svm_model.score(X_test_scaled, y_test_encoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Fit to a KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train_encoded)\n",
    "    train_score = knn.score(X_train_scaled, y_train_encoded)\n",
    "    test_score = knn.score(X_test_scaled, y_test_encoded)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "# Plot the results\n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o', label=\"training scores\")\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\", label=\"testing scores\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the KNN model with 3 neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_model.fit(X_train_scaled, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model by checking the model accuracy with model.score\n",
    "print(f\"Training Data Score: {knn_model.score(X_train_scaled, y_train_encoded)}\")\n",
    "print(f\"Testing Data Score: {knn_model.score(X_test_scaled, y_test_encoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Fit to a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decision tree classifier model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_model.fit(X_train_scaled, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model by checking the model accuracy with model.score\n",
    "print(f\"Training Data Score: {dt_model.score(X_train_scaled, y_train_encoded)}\")\n",
    "print(f\"Testing Data Score: {dt_model.score(X_test_scaled, y_test_encoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Fit to a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random forest classifier model\n",
    "# with n_estimators=128 and random_state=1\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train_scaled, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model by checking the model accuracy with model.score\n",
    "print(f\"Training Data Score: {rf_model.score(X_train_scaled, y_train_encoded)}\")\n",
    "print(f\"Testing Data Score: {rf_model.score(X_test_scaled, y_test_encoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Fit to a Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Gradient Boosting classifier\n",
    "clf = GradientBoostingClassifier(random_state=1).fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train_encoded)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test_encoded)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Fit to an Adaptive Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(random_state=1).fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train_encoded)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test_encoded)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
